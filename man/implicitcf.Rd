% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/implicitcf.R
\name{implicitcf}
\alias{implicitcf}
\title{Collaborative Filtering for Implicit Feedback Datasets}
\usage{
implicitcf(R, alpha = 1, C1 = alpha * R, P = (R > 0) * 1, f = 10,
  lambda = 0, init_stdv = ifelse(lambda == 0, 0.01, 1/sqrt(2 * lambda)),
  max_iters = 10, quiet = TRUE)
}
\arguments{
\item{R}{A sparse implicit feedback matrix, where the rows typically represent users
and the columns typically represent items. The elements of the matrix represent the
number of times that the users have interacted with the items}

\item{alpha}{Used to calculate cost matrix \code{C} = 1 + \code{alpha} * \code{R}
if \code{C1} is not specified}

\item{C1}{Equal the cost matrix (\code{C}) minus 1, which should be sparse}

\item{P}{A binary matrix, indicating whether or not the users interacted with the items}

\item{f}{The rank of the matrix factorization}

\item{lambda}{The L2 squared norm penalty on the latent row and column features}

\item{init_stdv}{Standard deviation to initialize the latent row and column features}

\item{max_iters}{How many iterations to run the algorithm for}

\item{quiet}{Whether or not to print out progress}
}
\value{
An S3 object of class \code{implicitcf} which is a list with the following components:
  \item{X}{the rank-\code{f} latent features for the users}
  \item{Y}{the rank-\code{f} latent features for the items}
  \item{loss_trace}{the loss function after each iteration. It should be non-increasing}
  \item{f}{the rank used}
  \item{lambda}{the penalty parameter used}
}
\description{
Collaborative Filtering for Implicit Feedback Datasets
}
\details{
This function impliments the algorithm of Hu et al. (2008) in R using sparse matrices.
  It solves for \code{X} and \code{Y} by minimizing the loss function:
  \deqn{\sum_{u, i} c_{ui} (p_{ui} - x_u^Ty_i)^2 + \lambda (||X||_F^2 + ||Y||_F^2)}

  It does this by iteratively solving for \eqn{x_u, u = 1, ...,}\code{nrow(R)} and
  \eqn{y_i, i = 1, ...,}\code{ncol(R)}, holding everything else constant.

  Since implicit feedback data is typically sparse, the algorithm and this code are optimized
  take advantage of the sparsity. That being said, the algorithm involves looping over
  the rows and columns of the matrix, which R is slow at.
}
\examples{
 X = matrix(rnorm(10 * 2, 0, 1), 10, 2)
 Y = matrix(rnorm(5 * 2, 0, 2), 5, 2)
 noise = matrix(rnorm(10 * 5, 0, 0.5), 10, 5)
 R = round(pmax(tcrossprod(X, Y) + noise, 0))

 icf = implicitcf(R, f = 2, alpha = 1, lambda = 0.1, quiet = FALSE)

 # should be decreasing
 plot(icf$loss_trace)

}
\references{
Hu, Y., Koren, Y., Volinsky, C., 2008. Collaborative filtering for implicit feedback datasets.
In Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on (pp. 263-272). IEEE.
}

